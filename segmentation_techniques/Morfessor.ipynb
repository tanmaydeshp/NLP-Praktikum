{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "* English sentences training file: https://github.com/sigmorphon/2022SegmentationST/blob/ac161e1107e423577e922b05f8c43c6ebad6722a/data/eng.sentence.train.tsv\n",
    "* English sentences test file: https://github.com/sigmorphon/2022SegmentationST/blob/ac161e1107e423577e922b05f8c43c6ebad6722a/data/eng.sentence.test.tsv\n",
    "* English sentences test gold file: https://github.com/sigmorphon/2022SegmentationST/blob/ac161e1107e423577e922b05f8c43c6ebad6722a/data/eng.sentence.test.gold.tsv\n",
    "* Tsez sentences training data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Tsez/ddo-train-track2-uncovered\n",
    "* Tsez sentences test data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Tsez/ddo-test-track2-uncovered\n",
    "* Natagu sentences training data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Natugu/ntu-train-track2-uncovered\n",
    "* Natagu sentences test data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Natugu/ntu-test-track2-uncovered\n",
    "* Lezgi sentences training data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Lezgi/lez-train-track2-uncovered\n",
    "* Lezgi sentences test data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Lezgi/lez-test-track2-uncovered\n",
    "* Gitskan sentences training data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Gitksan/git-train-track2-uncovered\n",
    "* Gitskan sentences test data: https://github.com/sigmorphon/2023glossingST/blob/259be10acad334feb36869eec05263b8b8fab436/data/Gitksan/git-test-track2-uncovered\n",
    "* Evaluation script: https://github.com/sigmorphon/2022SegmentationST/blob/ac161e1107e423577e922b05f8c43c6ebad6722a/evaluation/evaluate.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morfessor Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas morfessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7180\\1822670189.py:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  def train(type=\"standard\", morph_length=-1, num_morph_types=-1, bin_model_path=\"models\\m_morfessor.bin\", training_file_path=\"data\\\\training_morfessor_cli.txt\"):\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7180\\1822670189.py:18: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  def segment(bin_model_path=\"models\\m_morfessor.bin\", input_tsv=\"data\\\\eng.sentence.test.gold.tsv\", output_tsv=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\"):\n"
     ]
    }
   ],
   "source": [
    "#unsupervised\n",
    "import pandas as pd\n",
    "import morfessor\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def train(type=\"standard\", morph_length=-1, num_morph_types=-1, bin_model_path=\"models\\m_morfessor.bin\", training_file_path=\"data\\\\training_morfessor_cli.txt\"):\n",
    "  if type==\"standard\":\n",
    "    train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path, '--traindata-list', training_file_path])\n",
    "  elif type==\"morph_length\" and morph_length>0:\n",
    "    train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path,'--morph-length', f'{morph_length}', '--traindata-list', training_file_path])\n",
    "  elif type==\"num_morph_types\" and num_morph_types>0:\n",
    "     train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path,'--num-morph-types', f'{num_morph_types}', '--traindata-list', training_file_path])  \n",
    "  else:\n",
    "     print(\"Error in the training arguments!\")\n",
    "\n",
    "\n",
    "def segment(bin_model_path=\"models\\m_morfessor.bin\", input_tsv=\"data\\\\eng.sentence.test.gold.tsv\", output_tsv=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\"):\n",
    "\n",
    "  io = morfessor.MorfessorIO()\n",
    "  model = io.read_binary_model_file(bin_model_path)\n",
    "\n",
    "  df_guess = pd.read_csv(input_tsv, sep='\\t', header=None)\n",
    "  data_guess = df_guess[0].astype(str)\n",
    "  i = 0\n",
    "\n",
    "  #segment on words\n",
    "\n",
    "  for entry in data_guess:\n",
    "    sent = ''\n",
    "    j = 0\n",
    "    words = entry.split() #list of words\n",
    "    length_sent = len(words)  #number of words\n",
    "\n",
    "    for word in words:\n",
    "      list_word = model.viterbi_segment(word)[0]\n",
    "      k = 0\n",
    "      length_word = len(list_word)  #number of morphs\n",
    "\n",
    "      for morph in list_word:\n",
    "        if k != length_word - 1:  #not last morph\n",
    "          sent += (morph + ' @@')\n",
    "          k+=1\n",
    "        else: #last morph\n",
    "          if j != length_sent - 1:\n",
    "            sent += (morph + ' ')\n",
    "          else :\n",
    "            sent +=morph\n",
    "      j+=1\n",
    "\n",
    "    df_guess[1][i] = sent\n",
    "    i+=1\n",
    "\n",
    "  df_guess.to_csv(output_tsv, sep='\\t', header=None, index = False)\n",
    "\n",
    "\n",
    "def evaluate(type=\"standard\", gld=\"data\\\\eng.sentence.test.gold.tsv\", gs=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\", store=\"outputs\\\\eng.output.json\", morph_length=-1, num_morph_types=-1, training=False):\n",
    "  import argparse\n",
    "  args = argparse.Namespace(\n",
    "      gold=gld,\n",
    "      guess=gs,\n",
    "      output=store,\n",
    "      category=False \n",
    "  )\n",
    "  import evaluate, json, os\n",
    "  stats = evaluate.main(args)\n",
    "  model_name = \"morfessor_\"\n",
    "  if training: \n",
    "     model_name += \"training_\"\n",
    "  if type==\"standard\":\n",
    "     model_name += \"standard\"\n",
    "  elif type==\"morph_length\" and morph_length>0:\n",
    "     model_name += f\"len_{morph_length}\"\n",
    "  elif type==\"num_morph_types\" and num_morph_types>0:\n",
    "     model_name += f\"types_{num_morph_types}\"\n",
    "  else:\n",
    "     print(\"Error in arguments!\")\n",
    "  new_stats = {\"model\": model_name}\n",
    "  new_stats.update(stats)\n",
    "  data = {\"data\": []}\n",
    "  if os.path.exists(args.output):\n",
    "      with open(args.output, 'r') as output_file:\n",
    "          data = json.load(output_file)\n",
    "\n",
    "  # Skip adding data point if already present\n",
    "  if not any(item.get(\"model\") == model_name for item in data[\"data\"]):\n",
    "      data[\"data\"].append(new_stats)\n",
    "      data[\"data\"] = sorted(data[\"data\"], key=lambda x: x[\"model\"])\n",
    "      with open(args.output, 'w') as output_file:\n",
    "          json.dump(data, output_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Morfessor to the english sentences test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the standard evaluation without any flags to the JSON file\n",
    "train()\n",
    "segment()\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the evaluations for different --morph-length values to the JSON file\n",
    "\n",
    "# Find the average length of a word in the training file. Avg. morph length <= Avg. word length\n",
    "total_len = 0\n",
    "total_words = 0\n",
    "with open(\"data\\\\training_morfessor_cli.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for word in f: \n",
    "        total_words +=1\n",
    "        total_len += len(word)\n",
    "avg_len = 0\n",
    "if total_words!=0:\n",
    "    avg_len = int(total_len / total_words)\n",
    "print(avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,avg_len + 1):\n",
    "    train(type=\"morph_length\", morph_length=i)\n",
    "    segment()\n",
    "    evaluate(type=\"morph_length\", morph_length=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate how many distinct words are in the training file. num_morph_types <= num_distinct_words\n",
    "distinct_words = []\n",
    "with open(\"data\\\\training_morfessor_cli.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for word in file:\n",
    "        if word not in distinct_words:\n",
    "            distinct_words.append(word)\n",
    "num_distinct_words = len(distinct_words)\n",
    "print(num_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(500, num_distinct_words, 1000):\n",
    "    train(type=\"num_morph_types\", num_morph_types=j)\n",
    "    segment()\n",
    "    evaluate(type=\"num_morph_types\", num_morph_types=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9440\\1822670189.py:51: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_guess[1][i] = sent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "category: all\n",
      "distance\t2.93\n",
      "f_measure\t77.77\n",
      "precision\t83.31\n",
      "recall\t72.92\n"
     ]
    }
   ],
   "source": [
    "train(type=\"morph_length\", morph_length=6)\n",
    "segment()\n",
    "evaluate(type=\"morph_length\", morph_length=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Morfessor to the english sentences training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use morfessor to segment the training data itself \n",
    "train()\n",
    "segment(input_tsv=\"data\\\\eng.sentence.train.tsv\", output_tsv=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\")\n",
    "evaluate(gld=\"data\\\\eng.sentence.train.tsv\", gs=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\", training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record the f-score for the training data for different --morph-length values\n",
    "for i in range(1,avg_len + 2):\n",
    "    train(type=\"morph_length\", morph_length=i)\n",
    "    segment(input_tsv=\"data\\\\eng.sentence.train.tsv\", output_tsv=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\")\n",
    "    evaluate(type=\"morph_length\", morph_length=i, training=True, gld=\"data\\\\eng.sentence.train.tsv\", gs=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record the f-score for the training data for different --num-morph-types values\n",
    "for j in range(500, num_distinct_words, 1000):\n",
    "    train(type=\"num_morph_types\", num_morph_types=j)\n",
    "    segment(input_tsv=\"data\\\\eng.sentence.train.tsv\", output_tsv=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\")\n",
    "    evaluate(type=\"num_morph_types\", num_morph_types=j, training=True, gld=\"data\\\\eng.sentence.train.tsv\", gs=\"outputs\\\\eng.sentence.train.morfessor_guess.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Morfessor on 4 low-resource languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the standard evaluations for the 4 low-resource languages to the data\n",
    "langs = [\"ddo\", \"git\", \"lez\", \"ntu\"]\n",
    "for lang in langs: \n",
    "    train(training_file_path=f\"data\\\\{lang}.train.cli.txt\")\n",
    "    segment(input_tsv=f\"data\\\\{lang}.test.gold.tsv\", output_tsv=f\"outputs\\\\{lang}.sentence.test.morfessor_guess.tsv\")\n",
    "    evaluate(gld=f\"data\\\\{lang}.test.gold.tsv\", gs=f\"outputs\\\\{lang}.sentence.test.morfessor_guess.tsv\", store=f\"outputs\\\\{lang}.output.json\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the evaluations for different morph lengths for the 4 low-resource languages to the data\n",
    "for lang in langs: \n",
    "        for i in range(1,7):        \n",
    "                train(training_file_path=f\"data\\\\{lang}.train.cli.txt\", type=\"morph_length\", morph_length=i)\n",
    "                segment(input_tsv=f\"data\\\\{lang}.test.gold.tsv\", output_tsv=f\"outputs\\\\{lang}.sentence.test.morfessor_guess.tsv\")\n",
    "                evaluate(gld=f\"data\\\\{lang}.test.gold.tsv\", gs=f\"outputs\\\\{lang}.sentence.test.morfessor_guess.tsv\", store=f\"outputs\\\\{lang}.output.json\", type=\"morph_length\", morph_length=i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7180\\1822670189.py:51: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_guess[1][i] = sent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "category: all\n",
      "distance\t10.23\n",
      "f_measure\t50.65\n",
      "precision\t46.35\n",
      "recall\t55.83\n"
     ]
    }
   ],
   "source": [
    "train(training_file_path=f\"data\\\\ntu.train.cli.txt\")\n",
    "segment(input_tsv=f\"data\\\\ntu.test.gold.tsv\", output_tsv=f\"outputs\\\\ntu.sentence.test.morfessor_guess.tsv\")\n",
    "evaluate(gld=f\"data\\\\ntu.test.gold.tsv\", gs=f\"outputs\\\\ntu.sentence.test.morfessor_guess.tsv\", store=f\"outputs\\\\ntu.output.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
