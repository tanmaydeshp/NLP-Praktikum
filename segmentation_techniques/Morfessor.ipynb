{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: morfessor in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\documents\\code\\nlp-praktikum\\nlp-venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas morfessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7560\\1884829732.py:10: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  train = subprocess.run(['morfessor-train.bat', '-s', 'models\\m_morfessor.bin','--morph-length', f'{morph_length}', '--traindata-list', 'data\\\\training_morfessor_cli.txt'])\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7560\\1884829732.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_guess[1][i] = sent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "category: all\n",
      "distance\t2.71\n",
      "f_measure\t81.31\n",
      "precision\t82.78\n",
      "recall\t79.89\n"
     ]
    }
   ],
   "source": [
    "#unsupervised\n",
    "\n",
    "#TODO: Add command line script for training the model\n",
    "\n",
    "import pandas as pd\n",
    "import morfessor\n",
    "import subprocess\n",
    "import os\n",
    "morph_length = 5\n",
    "train = subprocess.run(['morfessor-train.bat', '-s', 'models\\m_morfessor.bin','--morph-length', f'{morph_length}', '--traindata-list', 'data\\\\training_morfessor_cli.txt'])\n",
    "\n",
    "input_tsv = 'data\\\\eng.sentence.test.gold.tsv'  #path to the input tsv file\n",
    "output_tsv = 'outputs\\\\eng.sentence.test.morfessor_guess.tsv'  #path tot the output tsv file\n",
    "bi_model = 'models\\\\m_morfessor.bin'\n",
    "\n",
    "io = morfessor.MorfessorIO()\n",
    "model = io.read_binary_model_file(bi_model)\n",
    "\n",
    "\n",
    "\n",
    "df_guess = pd.read_csv(input_tsv, sep='\\t', header=None)\n",
    "data_guess = df_guess[0].astype(str)\n",
    "i = 0\n",
    "\n",
    "#segment on words\n",
    "\n",
    "for entry in data_guess:\n",
    "  sent = ''\n",
    "  j = 0\n",
    "  words = entry.split() #list of words\n",
    "  length_sent = len(words)  #number of words\n",
    "\n",
    "  for word in words:\n",
    "    list_word = model.viterbi_segment(word)[0]\n",
    "    k = 0\n",
    "    length_word = len(list_word)  #number of morphs\n",
    "\n",
    "    for morph in list_word:\n",
    "      if k != length_word - 1:  #not last morph\n",
    "        sent += (morph + ' @@')\n",
    "        k+=1\n",
    "      else: #last morph\n",
    "        if j != length_sent - 1:\n",
    "          sent += (morph + ' ')\n",
    "        else :\n",
    "          sent +=morph\n",
    "    j+=1\n",
    "\n",
    "  df_guess[1][i] = sent\n",
    "  i+=1\n",
    "\n",
    "df_guess.to_csv(output_tsv, sep='\\t', header=None, index = False)\n",
    "\n",
    "import argparse\n",
    "args = argparse.Namespace(\n",
    "    gold=\"data\\\\eng.sentence.test.gold.tsv\",\n",
    "    guess=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\",\n",
    "    output=\"outputs\\\\output.json\",\n",
    "    category=False \n",
    ")\n",
    "import evaluate, json, os\n",
    "stats = evaluate.main(args)\n",
    "model_name = f\"morfessor_len_{morph_length}\"\n",
    "new_stats = {\"model\": model_name}\n",
    "new_stats.update(stats)\n",
    "data = {\"data\": []}\n",
    "if os.path.exists(args.output):\n",
    "    with open(args.output, 'r') as output_file:\n",
    "        data = json.load(output_file)\n",
    "\n",
    "# Skip adding data point if already present\n",
    "if not any(item.get(\"model\") == model_name for item in data[\"data\"]):\n",
    "    data[\"data\"].append(new_stats)\n",
    "    data[\"data\"] = sorted(data[\"data\"], key=lambda x: x[\"model\"])\n",
    "    with open(args.output, 'w') as output_file:\n",
    "        json.dump(data, output_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "category: all\n",
      "distance\t6.04\n",
      "f_measure\t59.72\n",
      "precision\t52.90\n",
      "recall\t68.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate_script_path = r'NLP-Praktikum\\segmentation_techniques\\evaluate.py'\n",
    "\n",
    "# try:\n",
    "#   eval = subprocess.run([r'C:\\Users\\admin\\Documents\\code\\NLP-Praktikum\\nlp-venv\\Scripts\\python.exe', 'evaluate.py', '--guess', 'outputs\\\\eng.sentence.test.morfessor_guess.tsv', '--gold', 'data\\\\eng.sentence.test.gold.tsv'] ,\n",
    "#                          capture_output=True,  \n",
    "#                          text=True,\n",
    "#                          check=True            \n",
    "#   )\n",
    "#   print(eval.stdout)\n",
    "# except subprocess.CalledProcessError as e:\n",
    "#   print(e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
