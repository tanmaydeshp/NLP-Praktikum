{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas morfessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised\n",
    "import pandas as pd\n",
    "import morfessor\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def train(type=\"standard\", morph_length=-1, num_morph_types=-1, bin_model_path=\"models\\m_morfessor.bin\", training_file_path=\"data\\\\training_morfessor_cli.txt\"):\n",
    "  if type==\"standard\":\n",
    "    train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path, '--traindata-list', training_file_path])\n",
    "  elif type==\"morph_length\" and morph_length>0:\n",
    "    train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path,'--morph-length', f'{morph_length}', '--traindata-list', training_file_path])\n",
    "  elif type==\"num_morph_types\" and num_morph_types>0:\n",
    "     train_res = subprocess.run(['morfessor-train.bat', '-s', bin_model_path,'--num-morph-types', f'{num_morph_types}', '--traindata-list', training_file_path])  \n",
    "  else:\n",
    "     print(\"Error in the training arguments!\")\n",
    "\n",
    "\n",
    "def segment(bin_model_path=\"models\\m_morfessor.bin\", input_tsv=\"data\\\\eng.sentence.test.gold.tsv\", output_tsv=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\"):\n",
    "\n",
    "  io = morfessor.MorfessorIO()\n",
    "  model = io.read_binary_model_file(bin_model_path)\n",
    "\n",
    "  df_guess = pd.read_csv(input_tsv, sep='\\t', header=None)\n",
    "  data_guess = df_guess[0].astype(str)\n",
    "  i = 0\n",
    "\n",
    "  #segment on words\n",
    "\n",
    "  for entry in data_guess:\n",
    "    sent = ''\n",
    "    j = 0\n",
    "    words = entry.split() #list of words\n",
    "    length_sent = len(words)  #number of words\n",
    "\n",
    "    for word in words:\n",
    "      list_word = model.viterbi_segment(word)[0]\n",
    "      k = 0\n",
    "      length_word = len(list_word)  #number of morphs\n",
    "\n",
    "      for morph in list_word:\n",
    "        if k != length_word - 1:  #not last morph\n",
    "          sent += (morph + ' @@')\n",
    "          k+=1\n",
    "        else: #last morph\n",
    "          if j != length_sent - 1:\n",
    "            sent += (morph + ' ')\n",
    "          else :\n",
    "            sent +=morph\n",
    "      j+=1\n",
    "\n",
    "    df_guess[1][i] = sent\n",
    "    i+=1\n",
    "\n",
    "  df_guess.to_csv(output_tsv, sep='\\t', header=None, index = False)\n",
    "\n",
    "\n",
    "def evaluate(type=\"standard\", gld=\"data\\\\eng.sentence.test.gold.tsv\", gs=\"outputs\\\\eng.sentence.test.morfessor_guess.tsv\", store=\"outputs\\\\output.json\", morph_length=-1, num_morph_types=-1):\n",
    "  import argparse\n",
    "  args = argparse.Namespace(\n",
    "      gold=gld,\n",
    "      guess=gs,\n",
    "      output=store,\n",
    "      category=False \n",
    "  )\n",
    "  import evaluate, json, os\n",
    "  stats = evaluate.main(args)\n",
    "  model_name = \"\"\n",
    "  if type==\"standard\":\n",
    "     model_name = \"morfessor_standard\"\n",
    "  elif type==\"morph_length\" and morph_length>0:\n",
    "     model_name = f\"morfessor_len_{morph_length}\"\n",
    "  elif type==\"num_morph_types\" and num_morph_types>0:\n",
    "     model_name = f\"morfessor_types_{num_morph_types}\"\n",
    "  else:\n",
    "     print(\"Error in arguments!\")\n",
    "  new_stats = {\"model\": model_name}\n",
    "  new_stats.update(stats)\n",
    "  data = {\"data\": []}\n",
    "  if os.path.exists(args.output):\n",
    "      with open(args.output, 'r') as output_file:\n",
    "          data = json.load(output_file)\n",
    "\n",
    "  # Skip adding data point if already present\n",
    "  if not any(item.get(\"model\") == model_name for item in data[\"data\"]):\n",
    "      data[\"data\"].append(new_stats)\n",
    "      data[\"data\"] = sorted(data[\"data\"], key=lambda x: x[\"model\"])\n",
    "      with open(args.output, 'w') as output_file:\n",
    "          json.dump(data, output_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the standard evaluation without any flags to the JSON file\n",
    "train()\n",
    "segment()\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Add the evaluations for different --morph-length values to the JSON file\n",
    "\n",
    "# Find the average length of a word in the training file\n",
    "total_len = 0\n",
    "total_words = 0\n",
    "with open(\"data\\\\training_morfessor_cli.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for word in f: \n",
    "        total_words +=1\n",
    "        total_len += len(word)\n",
    "avg_len = 0\n",
    "if total_words!=0:\n",
    "    avg_len = int(total_len / total_words)\n",
    "print(avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,avg_len + 1):\n",
    "    train(type=\"morph_length\", morph_length=i)\n",
    "    segment()\n",
    "    evaluate(type=\"morph_length\", morph_length=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
